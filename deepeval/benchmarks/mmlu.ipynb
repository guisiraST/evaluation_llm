{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MMLU (Massive Multitask Language Understanding) เป็น benchmark ที่ใช้สำหรับวัดประเมิน LLM ด้วย multiple-choice-question ที่รวบรวมกว่า 57 เรื่อง เช่น เลข ประวัติศาสตร์ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arguments\n",
    "- [Optional] tasks: a list of tasks (MMLUTask enums), specifying which of the 57 subject areas to evaluate in the language model. By default, this is set to all tasks. Detailed descriptions of the MMLUTask enum can be found here.\n",
    "- [Optional] n_shots: the number of \"shots\" to use for few-shot learning. This is set to 5 by default and cannot exceed this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/deepeval/__init__.py:42: UserWarning: You are using deepeval version 0.21.42, however version 0.21.45 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "import sys\n",
    "sys.path.append('/opt/project/src/evaluate_llm/')\n",
    "from api_key_config import settings\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_VERSION\"] = settings.OPENAI_API_VERSION\n",
    "os.environ[\"OPENAI_API_KEY\"] = settings.OPENAI_API_KEY\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = settings.AZURE_OPENAI_ENDPOINT\n",
    "\n",
    "class AzureOpenAI(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model\n",
    "    ):\n",
    "        self.model = model\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        return chat_model.invoke(prompt).content\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        res = await chat_model.ainvoke(prompt)\n",
    "        return res.content\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"Custom Azure OpenAI Model\"\n",
    "\n",
    "# Replace these with real values\n",
    "custom_model = AzureChatOpenAI(\n",
    "    deployment_name=\"gpt-35-turbo\",\n",
    ")\n",
    "azure_openai = AzureOpenAI(model=custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.benchmarks import MMLU\n",
    "from deepeval.benchmarks.tasks import MMLUTask\n",
    "\n",
    "# Define benchmark with specific tasks and shots\n",
    "benchmark = MMLU(\n",
    "    tasks=[MMLUTask.HIGH_SCHOOL_COMPUTER_SCIENCE],\n",
    "    n_shots=3\n",
    ")\n",
    "\n",
    "# Replace 'mistral_7b' with your own custom model\n",
    "benchmark.evaluate(model=azure_openai)\n",
    "print(benchmark.overall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall_score for this benchmark ranges from 0 to 1, where 1 signifies perfect performance and 0 indicates no correct answers. The model's score, based on exact matching, is calculated by determining the proportion of multiple-choice questions for which the model produces the precise correct letter answer (e.g. 'A') in relation to the total number of questions.\n",
    "\n",
    "As a result, utilizing more few-shot prompts (n_shots) can greatly improve the model's robustness in generating answers in the exact correct format and boost the overall score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
