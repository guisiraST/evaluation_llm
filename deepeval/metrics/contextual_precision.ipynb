{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contextual Precision ใช้สำหรับการประเมิน RAG โดยประเมินจาก retrieval_context ว่ามีความเกี่ยวข้องกับ input ไหม \n",
    "\n",
    "### Required Arguments\n",
    "- input\n",
    "- actual_output\n",
    "- expected_output\n",
    "- retrieval_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/deepeval/__init__.py:42: UserWarning: You are using deepeval version 0.21.42, however version 0.21.45 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "import sys\n",
    "sys.path.append('/opt/project/src/evaluate_llm/')\n",
    "from api_key_config import settings\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_VERSION\"] = settings.OPENAI_API_VERSION\n",
    "os.environ[\"OPENAI_API_KEY\"] = settings.OPENAI_API_KEY\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = settings.AZURE_OPENAI_ENDPOINT\n",
    "\n",
    "class AzureOpenAI(DeepEvalBaseLLM):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model\n",
    "    ):\n",
    "        self.model = model\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        return chat_model.invoke(prompt).content\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        res = await chat_model.ainvoke(prompt)\n",
    "        return res.content\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"Custom Azure OpenAI Model\"\n",
    "\n",
    "# Replace these with real values\n",
    "custom_model = AzureChatOpenAI(\n",
    "    deployment_name=\"gpt-35-turbo\",\n",
    ")\n",
    "azure_openai = AzureOpenAI(model=custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6f09b3a1614e709c15fbd98026e37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Event loop is already running. Applying nest_asyncio patch to allow async execution...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56a12bdc86742c8940aca3d0bd51a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "The score is 0.00 because the only retrieval context provided has a 'no' verdict and the reason for the 'no' verdict is that \"The context does not address the question about the shoes not fitting, it only mentions the refund policy.\" This shows that the relevant nodes are not ranked higher than irrelevant nodes, resulting in a low contextual precision score.\n",
      "Evaluating test cases...\n",
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Contextual Precision (score: 0, threshold: 0.7, strict: False, evaluation model: Custom Azure OpenAI Model, reason: The score is 0.00 because the only node in the retrieval context received a 'no' verdict and was ranked as the only node. Therefore, there were no relevant nodes ranked higher than irrelevant nodes, resulting in a low contextual precision score., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What if these shoes don't fit?\n",
      "  - actual output: We offer a 30-day full refund at no extra cost.\n",
      "  - expected output: You are eligible for a 30 day full refund at no extra cost.\n",
      "  - context: None\n",
      "  - retrieval context: ['All customers are eligible for a 30 day full refund at no extra cost.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "ContextualPrecisionMetric: 0.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/portalocker/utils.py:218: UserWarning: timeout has no effect in blocking mode\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Tests finished! Run <span style=\"color: #008000; text-decoration-color: #008000\">\"deepeval login\"</span> to view evaluation results on the web.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Tests finished! Run \u001b[32m\"deepeval login\"\u001b[0m to view evaluation results on the web.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[TestResult(success=False, metrics=[<deepeval.metrics.contextual_precision.contextual_precision.ContextualPrecisionMetric object at 0x7fbc046d66a0>], input=\"What if these shoes don't fit?\", actual_output='We offer a 30-day full refund at no extra cost.', expected_output='You are eligible for a 30 day full refund at no extra cost.', context=None, retrieval_context=['All customers are eligible for a 30 day full refund at no extra cost.'])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import ContextualPrecisionMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "\n",
    "# Replace this with the actual output from your LLM application\n",
    "actual_output = \"We offer a 30-day full refund at no extra cost.\"\n",
    "\n",
    "# Replace this with the expected output from your RAG generator\n",
    "expected_output = \"You are eligible for a 30 day full refund at no extra cost.\"\n",
    "\n",
    "# Replace this with the actual retrieved context from your RAG pipeline\n",
    "retrieval_context = [\"All customers are eligible for a 30 day full refund at no extra cost.\"]\n",
    "\n",
    "metric = ContextualPrecisionMetric(\n",
    "    threshold=0.7,\n",
    "    model=azure_openai,\n",
    "    include_reason=True\n",
    ")\n",
    "test_case = LLMTestCase(\n",
    "    input=\"What if these shoes don't fit?\",\n",
    "    actual_output=actual_output,\n",
    "    expected_output=expected_output,\n",
    "    retrieval_context=retrieval_context\n",
    ")\n",
    "\n",
    "metric.measure(test_case)\n",
    "print(metric.score)\n",
    "print(metric.reason)\n",
    "\n",
    "# or evaluate test cases in bulk\n",
    "evaluate([test_case], [metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are five optional parameters when creating a ContextualPrecisionMetric:\n",
    "\n",
    "- [Optional] threshold: a float representing the minimum passing threshold, defaulted to 0.5.\n",
    "- [Optional] model: a string specifying which of OpenAI's GPT models to use, OR any custom LLM model of type DeepEvalBaseLLM. Defaulted to 'gpt-4o'.\n",
    "- [Optional] include_reason: a boolean which when set to True, will include a reason for its evaluation score. Defaulted to True.\n",
    "- [Optional] strict_mode: a boolean which when set to True, enforces a binary metric score: 1 for perfection, 0 otherwise. It also overrides the current threshold and sets it to 1. Defaulted to False.\n",
    "- [Optional] async_mode: a boolean which when set to True, enables concurrent execution within the measure() method. Defaulted to True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Is It Calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](contextual_precision_formular.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ข้อมูลเพิ่มเติม:\n",
    "- \\(k\\) คือโหนดลำดับที่ (i+1) ใน retrieval_context\n",
    "- \\(n\\) คือความยาวของ retrieval_context\n",
    "- \\(r_k\\) คือค่า relevance แบบไบนารีสำหรับโหนดที่ \\(k\\) ใน retrieval_context ซึ่ง \\(r_k = 1\\) สำหรับโหนดที่เกี่ยวข้อง และ \\(0\\) สำหรับโหนดที่ไม่เกี่ยวข้อง\n",
    "\n",
    "ContextualPrecisionMetric ใช้ LLM เพื่อกำหนดว่าโหนดแต่ละตัวใน retrieval_context นั้นเกี่ยวข้องกับ input หรือไม่ โดยพิจารณาข้อมูลจาก expected_output จากนั้นจะคำนวณ weighted cumulative precision เป็นคะแนนความแม่นยำเชิงบริบท\n",
    "\n",
    "Weighted cumulative precision (WCP) ถูกใช้เพราะว่า:\n",
    "- เน้นผลลัพธ์ที่อยู่ลำดับต้นๆ: WCP ให้ความสำคัญกับความเกี่ยวข้องของผลลัพธ์ที่ถูกจัดอันดับต้นๆ มากกว่า ซึ่งสำคัญเนื่องจาก LLM มักให้ความสำคัญกับโหนดที่อยู่ลำดับต้นๆ ใน retrieval_context (ซึ่งอาจทำให้เกิดการแสดงผลที่ผิดพลาดถ้าโหนดถูกจัดอันดับไม่ถูกต้อง)\n",
    "- ให้รางวัลการจัดอันดับที่เกี่ยวข้อง: WCP สามารถจัดการกับระดับความเกี่ยวข้องที่แตกต่างกันได้ (เช่น \"เกี่ยวข้องมาก\", \"ค่อนข้างเกี่ยวข้อง\", \"ไม่เกี่ยวข้อง\") ซึ่งแตกต่างจากเมตริกเช่น precision ที่ถือว่าโหนดที่ถูกดึงกลับทั้งหมดมีความสำคัญเท่าเทียมกัน\n",
    "\n",
    "คะแนนความแม่นยำเชิงบริบทที่สูงกว่าหมายถึงความสามารถที่มากขึ้นของระบบการดึงข้อมูลในการจัดอันดับโหนดที่เกี่ยวข้องสูงขึ้นใน retrieval_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
