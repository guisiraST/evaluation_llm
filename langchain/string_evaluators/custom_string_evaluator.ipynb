{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom String Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เราสามารถที่จะสร้างแบบประเมิน custom string evaluators ได้โดยใช้ StringEvaluators ตัวอย่างเช่นเราสามารถสร้างประเมินผ่านเมทริก perplexity โดยใช้ไลรารี่จาก huggingface \n",
    "เพื่อวัดข้อความที่ gen ออกมาดีแค่ไหน หรืออาจจะนำไปใช้กับ BELU score, ROUGH score ได้  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional\n",
    "\n",
    "from evaluate import load\n",
    "from langchain.evaluation import StringEvaluator\n",
    "\n",
    "\n",
    "class PerplexityEvaluator(StringEvaluator):\n",
    "    \"\"\"Evaluate the perplexity of a predicted string.\"\"\"\n",
    "\n",
    "    def __init__(self, model_id: str = \"gpt2\"):\n",
    "        self.model_id = model_id\n",
    "        self.metric_fn = load(\n",
    "            \"perplexity\", module_type=\"metric\", model_id=self.model_id, pad_token=0\n",
    "        )\n",
    "\n",
    "    def _evaluate_strings(\n",
    "        self,\n",
    "        *,\n",
    "        prediction: str,\n",
    "        reference: Optional[str] = None,\n",
    "        input: Optional[str] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> dict:\n",
    "        results = self.metric_fn.compute(\n",
    "            predictions=[prediction], model_id=self.model_id\n",
    "        )\n",
    "        ppl = results[\"perplexities\"][0]\n",
    "        return {\"score\": ppl}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c874922a4ffc4358b2b0422e73f0dcd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88aa9f04d4f743c1830d1e887144a005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b152eceed504de4bc6903b3fb41df5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61691d66cf5a49a5807e7f851ce27568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbea3b913ead4d16a5da31bada571180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0f6f23525a48fabcdd0f39f7fa411f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38af43c2722a4481845a565c979ca5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'score': 190.36891174316406}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = PerplexityEvaluator()\n",
    "evaluator.evaluate_strings(prediction=\"The rains in Spain fall mainly on the plain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "อยากตัวอย่างใช้โมเดล GPT2 ในการหา perplexity หากจะใช้ openai gpt ไม่น่าทำได้เนื่องจากเป็นการ call API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
