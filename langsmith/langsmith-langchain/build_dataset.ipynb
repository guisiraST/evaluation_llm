{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset: Manually Curated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/project/src/evaluate_llm/')\n",
    "\n",
    "from api_key_config import settings\n",
    "import os\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = settings.LANGCHAIN_TRACING_V2\n",
    "os.environ['LANGCHAIN_API_KEY'] = settings.LANGCHAIN_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# QA\n",
    "inputs = [\n",
    "    \"How many tokens was DBRX pre-trained on?\",\n",
    "    \"Is DBRX a MOE model and how many parameters does it have?\",\n",
    "    \"How many GPUs was DBRX trained on and what was the connectivity between GPUs?\",\n",
    "]\n",
    "\n",
    "outputs = [\n",
    "    \"DBRX was pre-trained on 12 trillion tokens of text and code data.\",\n",
    "    \"Yes, DBRX is a fine-grained mixture-of-experts (MoE) architecture with 132B total parameters.\",\n",
    "    \"DBRX was trained on 3072 NVIDIA H100s connected by 3.2Tbps Infiniband\",\n",
    "]\n",
    "\n",
    "# Dataset\n",
    "# qa_pairs = [{\"question\": q, \"answer\": a} for q, a in zip(inputs, outputs)]\n",
    "# df = pd.DataFrame(qa_pairs)\n",
    "\n",
    "# Write to csv\n",
    "# csv_path = \"/Users/rlm/Desktop/DBRX_eval.csv\"\n",
    "# df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"DBRX\"\n",
    "\n",
    "# Store\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"QA pairs about DBRX model.\",\n",
    ")\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in inputs],\n",
    "    outputs=[{\"answer\": a} for a in outputs],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# update dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_questions = [\n",
    "    \"What is the context window of DBRX Instruct?\",\n",
    "]\n",
    "\n",
    "new_answers = [\n",
    "    \"DBRX Instruct was trained with up to a 32K token context window.\",\n",
    "]\n",
    "\n",
    "# See updated version in the UI\n",
    "client.create_examples(\n",
    "    inputs=[{\"question\": q} for q in new_questions],\n",
    "    outputs=[{\"answer\": a} for a in new_answers],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See result dataset in https://smith.langchain.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](build_dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
